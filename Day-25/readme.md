# Day 25 of [#100DaysOfCode](https://twitter.com/Param3021/status/1541716679163789312)

## Task
1. Feature Engineering Course
2. House price prediction

# Resources
- Kaggle's [Feature Engineering Course](https://www.kaggle.com/learn/feature-engineering)
- - Lesson 1: [What is Feature Engineering](https://www.kaggle.com/code/ryanholbrook/what-is-feature-engineering)
- - Lesson 2: [Mutual Information](https://www.kaggle.com/code/ryanholbrook/mutual-information) - [My Notebook](https://www.kaggle.com/param302/exercise-mutual-information)

- Kaggle [House price prediction Challenge](https://www.kaggle.com/competitions/home-data-for-ml-course/)
- - [My Notebook 1](https://www.kaggle.com/param302/house-price-prediction-11)


### Topics I have learnt
1. Feature Engineering
- What is Feature Engineering
- How is it useful for making Models
- Mutual Information    (shows every kind of relation in data with target)
2. Did house price prediction 
- With `XGBRegressor` & Mutual Information (high MI 50 columns)

### Software used
- Jupyter Notebook
- Python 3.10.2
- Numpy 1.22.4
- pandas 1.4.2
- Matplotlib 3.5.2
- Seaborn 0.11.2
- scikit-learn 1.1.1
- XGBoost 1.6.1

### My Notebooks
- [L2 - Mutual Information](./L2%20-%20Mutual_information.ipynb)
- [House_price_prediction_9.ipynb](./House_price_prediction_11.ipynb)

### Conclusion:
Today I learned What is Feature Engineering, How to make data better for ML models and Mutual Information. Also did house price prediction using Mutual Information of 50 columns having high MI.
